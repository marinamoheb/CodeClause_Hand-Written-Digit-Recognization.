{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4t6YjLvtGzB",
        "outputId": "8527e03d-2073-480e-e2ee-c1f9a13f5ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "# convert class vectors to binary class matrices\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=\"adam\",metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WL9k9gO5tkBD"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
        "model.fit(x_train, y_train,batch_size=200,epochs=10,verbose=1,validation_data=(x_test, y_test))\n",
        "# Final evaluation of the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zQ68-gkuUsA",
        "outputId": "d5d4446d-d24c-4bf7-fa80-c1518b6d2b30"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 [==============================] - 145s 480ms/step - loss: 0.2156 - accuracy: 0.9334 - val_loss: 0.0495 - val_accuracy: 0.9845\n",
            "Epoch 2/10\n",
            "300/300 [==============================] - 137s 457ms/step - loss: 0.0691 - accuracy: 0.9788 - val_loss: 0.0392 - val_accuracy: 0.9876\n",
            "Epoch 3/10\n",
            "300/300 [==============================] - 137s 458ms/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 0.0356 - val_accuracy: 0.9886\n",
            "Epoch 4/10\n",
            "300/300 [==============================] - 141s 470ms/step - loss: 0.0386 - accuracy: 0.9883 - val_loss: 0.0307 - val_accuracy: 0.9891\n",
            "Epoch 5/10\n",
            "300/300 [==============================] - 138s 461ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0265 - val_accuracy: 0.9919\n",
            "Epoch 6/10\n",
            "300/300 [==============================] - 137s 457ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0256 - val_accuracy: 0.9915\n",
            "Epoch 7/10\n",
            "300/300 [==============================] - 137s 457ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0245 - val_accuracy: 0.9915\n",
            "Epoch 8/10\n",
            "300/300 [==============================] - 137s 457ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0273 - val_accuracy: 0.9911\n",
            "Epoch 9/10\n",
            "300/300 [==============================] - 137s 457ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0263 - val_accuracy: 0.9916\n",
            "Epoch 10/10\n",
            "300/300 [==============================] - 136s 453ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0305 - val_accuracy: 0.9916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdulC2IZ0kRo",
        "outputId": "cce4b276-d7ca-452b-900b-0be694800750"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.030457446351647377\n",
            "Test accuracy: 0.991599977016449\n"
          ]
        }
      ]
    }
  ]
}